{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like   to  \tProgram the a  on in  in Python Language. Don’t you?   1   \n",
      "Dont I Language Program Python like to you\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# *******************\n",
    "# P1 convert string\n",
    "# *******************\n",
    "def convertString(line):\n",
    "    # Define common articles\n",
    "    common_articles = [' a ',' an ',' the ',' on ',' in '] \n",
    "\n",
    "    # Remove special character\n",
    "    line = ' '.join(re.sub('[^a-zA-Z ]', '', line).strip().split())\n",
    "\n",
    "    # Remove common articles from string\n",
    "    for item in common_articles:\n",
    "        line = re.sub(item,' ',line)  \n",
    "\n",
    "    # Sort the words in alphabetical order    \n",
    "    list_works = line.split(' ')\n",
    "    list_works.sort(key=lambda x:x.split()[-1])\n",
    "    \n",
    "    return ' '.join(list_works)\n",
    "\n",
    "line = 'I like   to  \tProgram the a  on in  in Python Language. Don’t you?   1   '\n",
    "line1 = 'don i language like program python  t you'\n",
    "print(line)  \n",
    "\n",
    "print(convertString('I like   to  \tProgram   in Python Language. Don’t you?')) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# *******************\n",
    "# P2 Unit test for method convert string\n",
    "# *******************\n",
    "def assertP2(input1, ouput1):\n",
    "    print(convertString(input1) == ouput1)\n",
    "    \n",
    "# testcase 1: Do not contain separator like ,./”:|;\\-[]()?. …\n",
    "input1 = 'love !@@#$%#$^%^&^$*()<>?:;/][[]]'\n",
    "ouput1 = 'love'\n",
    "assertP2(input1,ouput1)\n",
    "\n",
    "# testcase 2: Accept only single space, digit or alphabetic word.\n",
    "input1 = 'love !@@#$%#$^%^&^$*()<>?:;/][[]] you'\n",
    "ouput1 = 'love you'\n",
    "assertP2(input1,ouput1)\n",
    "\n",
    "# testcase 3: Do not contain any common articles like “a”, “the”, “on”, “in”…\n",
    "input1 = 'a love is the happy on people and in the world!'\n",
    "ouput1 = 'a and happy is love people world'\n",
    "assertP2(input1,ouput1)\n",
    "\n",
    "# testcase 4: a and happy is love people world\n",
    "input1 = 'work you i a lone love him'\n",
    "ouput1 = 'him i lone love work you'\n",
    "assertP2(input1,ouput1)\n",
    "\n",
    "# testcase 5: full test\n",
    "input1 = 'I like   to  \tProgram   in Python Language. Don’t you?' \n",
    "ouput1 = 'Dont I Language Program Python like to you'\n",
    "assertP2(input1,ouput1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('Dont',): 1, ('I',): 1, ('Language',): 1, ('Program',): 1, ('Python',): 1, ('like',): 1, ('to',): 1, ('you',): 1})\n",
      "Counter({('Dont', 'I'): 1, ('I', 'Language'): 1, ('Language', 'Program'): 1, ('Program', 'Python'): 1, ('Python', 'like'): 1, ('like', 'to'): 1, ('to', 'you'): 1})\n",
      "Counter({('Dont', 'I', 'Language'): 1, ('I', 'Language', 'Program'): 1, ('Language', 'Program', 'Python'): 1, ('Program', 'Python', 'like'): 1, ('Python', 'like', 'to'): 1, ('like', 'to', 'you'): 1})\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "# nltk.download('punkt') # donwload model punkt one time\n",
    "\n",
    "# *******************\n",
    "# P3 Generater Unigrams, Bigrams, Trigrams from output P1\n",
    "# *******************\n",
    "def generateUniBiTri(word):\n",
    "    # tokenize word\n",
    "    token = word_tokenize(word)\n",
    "    \n",
    "    # generate ngrams\n",
    "    unigrams = ngrams(token,1)\n",
    "    bigrams = ngrams(token,2)\n",
    "    trigrams = ngrams(token,3) \n",
    "    \n",
    "    return [unigrams, bigrams, trigrams]\n",
    "\n",
    "\n",
    "# Test P3 funtion\n",
    "input1 = 'I like   to  \tProgram   in Python Language. Don’t you?' \n",
    "text = convertString(input1)\n",
    "ouput_generate = generateUniBiTri(text)\n",
    "\n",
    "print(Counter(ouput_generate[0]))\n",
    "print(Counter(ouput_generate[1]))\n",
    "print(Counter(ouput_generate[2]))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-92-70dc55703d84>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-92-70dc55703d84>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    scrapy shell 'https://vnexpress.net/khoa-hoc'\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "scrapy shell 'https://vnexpress.net/khoa-hoc'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
